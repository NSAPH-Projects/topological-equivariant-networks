#@package _global_

model:
  # task defaults, can be overwritten by baseline
  _target_: etnn.models.ETNN
  num_out: 1
  adjacencies: ["0_0", "0_1", "1_1", "1_2", "2_2"]
  num_hidden: 32
  num_layers: 4
  num_readout_layers: 2
  depth_etnn_layers: 1
  jit: false

loader:
  _target_: torch.utils.data.DataLoader
  num_workers: 1
  batch_size: 1
  persistent_workers: true

dataset:
  _target_: etnn.pm25.utils.SpatialCC
  root: ./data
  force_reload: true
  pre_transform: 
    _target_: etnn.pm25.utils.standardize_cc
    _partial_: true
  transform:
    _target_: etnn.pm25.utils.create_mask
    seed: ${seed}   
    _partial_: true

collate_fn:
  _target_: etnn.combinatorial_complexes.CombinatorialComplexCollater
  follow_batch: ["cell_0", "cell_1", "cell_2"]

logger:
  - _target_: lightning.pytorch.loggers.WandbLogger
    log_model: all
    entity: ten-harvard
    project: spatial-cc

trainer:
  _target_: lightning.pytorch.Trainer
  max_epochs: 100
  accelerator: auto
  gradient_clip_val: 10
  callbacks:
    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: epoch

optimizer:
  _target_: torch.optim.Adam
  lr: 0.0003
  weight_decay: 1e-6

lr_scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: 0.001
  final_div_factor: 1e2
  epochs: 100
  steps_per_epoch: 100

criterion: mse # choose mse/mae