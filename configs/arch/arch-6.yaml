#@package _global_
defaults:
  - _self_
  - override /loss_fn: huber

model:
  num_out: 1
  num_hidden: 4
  num_layers: 4
  num_readout_layers: 1
  depth_etnn_layers: 1
  dropout: 0.25

optimizer:
  lr: 0.001
  weight_decay: 1e-3

lr_scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  eta_min: 0.0003
  T_max: ${training.max_epochs}

training:
  clip: 1.0

# this one will fail with graphs
dataset:
  version: v2
  transform:
    _target_: torch_geometric.transforms.compose.Compose
    _args_:
      - - _target_: etnn.pm25.utils.create_mask
          _partial_: true
          seed: ${seed}
          rate: 0.2
        # - _target_: etnn.pm25.utils.randomize
        #   _partial_: true
        #   keys: ['x_0']
        # - _target_: etnn.pm25.utils.x1_labels
        #   _partial_: true
        # - _target_: etnn.pm25.utils.squash_cc
        #   _partial_: true
        #   soft: true
