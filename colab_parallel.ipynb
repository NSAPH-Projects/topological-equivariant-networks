{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmLl5idn38kO",
        "outputId": "84abe8c6-5632-421c-d82d-1d31cdb682b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'topological-equivariant-networks' already exists and is not an empty directory.\n",
            "/content/topological-equivariant-networks\n"
          ]
        }
      ],
      "source": [
        "# Repo download (from colab-notebooks branch)\n",
        "%cd /content\n",
        "!git clone -b colab-notebooks https://github.com/NSAPH-Projects/topological-equivariant-networks.git\n",
        "%cd topological-equivariant-networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AdHRWxnUORX",
        "outputId": "5cfda0e3-8cb1-4d31-982d-13ffaf5c33a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIMFu2_gDgD2",
        "outputId": "321c56ea-885d-4a95-e99b-e91255053cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "  # Create the requirements.txt file\n",
        "%%writefile requirements.txt\n",
        "gudhi==3.8.0\n",
        "rdkit\n",
        "torch==2.1.0\n",
        "torch_geometric\n",
        "wandb\n",
        "git+https://github.com/pyt-team/TopoNetX@cede811485aefcff1d013dbb94942e8f92ac5d05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ5MWb1MEYTv",
        "outputId": "7a825d24-a696-4a5e-f29d-7b225df2d35c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/pyt-team/TopoNetX@cede811485aefcff1d013dbb94942e8f92ac5d05 (from -r requirements.txt (line 6))\n",
            "  Cloning https://github.com/pyt-team/TopoNetX (to revision cede811485aefcff1d013dbb94942e8f92ac5d05) to /tmp/pip-req-build-zkgj6kac\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyt-team/TopoNetX /tmp/pip-req-build-zkgj6kac\n",
            "  Running command git rev-parse -q --verify 'sha^cede811485aefcff1d013dbb94942e8f92ac5d05'\n",
            "  Running command git fetch -q https://github.com/pyt-team/TopoNetX cede811485aefcff1d013dbb94942e8f92ac5d05\n",
            "  Running command git checkout -q cede811485aefcff1d013dbb94942e8f92ac5d05\n",
            "  Resolved https://github.com/pyt-team/TopoNetX to commit cede811485aefcff1d013dbb94942e8f92ac5d05\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gudhi==3.8.0 (from -r requirements.txt (line 1))\n",
            "  Downloading gudhi-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit (from -r requirements.txt (line 2))\n",
            "  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.1.0 (from -r requirements.txt (line 3))\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_geometric (from -r requirements.txt (line 4))\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r requirements.txt (line 5))\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from gudhi==3.8.0->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->-r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (4.2.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.1)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading sentry_sdk-2.2.0-py2.py3-none-any.whl (281 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.1/281.1 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from TopoNetX==0.0.2->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TopoNetX==0.0.2->-r requirements.txt (line 6)) (2.0.3)\n",
            "Collecting trimesh (from TopoNetX==0.0.2->-r requirements.txt (line 6))\n",
            "  Downloading trimesh-4.4.0-py3-none-any.whl (694 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.6/694.6 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spharapy (from TopoNetX==0.0.2->-r requirements.txt (line 6))\n",
            "  Downloading SpharaPy-1.1.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 5)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->-r requirements.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->TopoNetX==0.0.2->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TopoNetX==0.0.2->-r requirements.txt (line 6)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TopoNetX==0.0.2->-r requirements.txt (line 6)) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->-r requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: TopoNetX\n",
            "  Building wheel for TopoNetX (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TopoNetX: filename=TopoNetX-0.0.2-py3-none-any.whl size=104433 sha256=be15955bb580e8d6259124fe6807c911e71a800d2a9effa23b7e2686177d9e52\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/63/ca/e5429d5616ccfc4c1e8432dbdd21e84a23198474877d5d5663\n",
            "Successfully built TopoNetX\n",
            "Installing collected packages: spharapy, triton, trimesh, smmap, setproctitle, sentry-sdk, rdkit, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gudhi, docker-pycreds, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, torch_geometric, TopoNetX, nvidia-cusolver-cu12, gitpython, wandb, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TopoNetX-0.0.2 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 gudhi-3.8.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 rdkit-2023.9.6 sentry-sdk-2.2.0 setproctitle-1.3.3 smmap-5.0.1 spharapy-1.1.2 torch-2.1.0 torch_geometric-2.5.3 trimesh-4.4.0 triton-2.1.0 wandb-0.17.0\n"
          ]
        }
      ],
      "source": [
        "# Create the environment\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPfxlFLxVUCq",
        "outputId": "b1f45976-a372-4562-dc14-3ac584ee07f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cL3O3pPTOCQH",
        "outputId": "88850db1-f7a5-420b-d137-90cb4ba78b77"
      },
      "outputs": [],
      "source": [
        "!source scripts/experiments/parallel_template.sh 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgb5P7Dye3dR",
        "outputId": "b7748418-ade5-4353-85a4-e4d2822792ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set as 42\n",
            "Random seed set as 42\n",
            "Random seed set as 42\n",
            "Random seed set as 42\n",
            "Number of parameters: 1497871\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "Number of parameters: 1497871\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "Number of parameters: 1497871\n",
            "Number of parameters: 1497871\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_161255-5i7zzh5f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgentle-dream-139\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/5i7zzh5f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_161255-q8k7jrvs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mradiant-glade-141\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/q8k7jrvs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_161255-zxb0x4o9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdainty-energy-139\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/zxb0x4o9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_161255-ma1d19ia\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfancy-aardvark-141\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/ma1d19ia\u001b[0m\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:43<00:00, 964.52it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:43<00:00, 963.83it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:43<00:00, 963.68it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:43<00:00, 961.61it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:28<00:00, 1130.18it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:28<00:00, 1127.74it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:28<00:00, 1125.80it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:29<00:00, 1115.62it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11376.61it/s]\n",
            "Preparing data: 100% 100000/100000 [00:09<00:00, 11064.09it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11158.37it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11476.28it/s]\n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:21<00:00, 832.25it/s] \n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:21<00:00, 843.31it/s] \n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:21<00:00, 831.41it/s] \n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:20<00:00, 850.60it/s] \n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:16<00:00, 1080.84it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:16<00:00, 1093.34it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:16<00:00, 1086.46it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:16<00:00, 1062.99it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 11770.88it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 11704.40it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 11784.99it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 11605.60it/s]\n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:20<00:00, 653.97it/s] \n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:20<00:00, 649.23it/s] \n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:20<00:00, 646.44it/s] \n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:19<00:00, 664.99it/s] \n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1167.57it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1159.47it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1150.40it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1162.86it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11607.43it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11735.67it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11785.33it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11668.13it/s]\n",
            "100% 200/200 [8:09:15<00:00, 146.78s/it]\n",
            "Test MAE: 0.021284252554722077\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▄▆▄▅▄▆▆▅▄▆▇▅▃▅▃▂▄▃▄▄▄▃▂▃▁▃▄▄▄█▃█▄▇▄▆▅▇▅▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE ▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁█▄▄▂▂▁▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE ▅▃▃▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁█▅▄▂▂▂▇▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 146.08101\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.02128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.01752\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.02156\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfancy-aardvark-141\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/ma1d19ia\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_161255-ma1d19ia/logs\u001b[0m\n",
            "100% 200/200 [8:10:15<00:00, 147.08s/it]\n",
            "Test MAE: 0.09044490847056799\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▅▆▆▅▆▆▆▅▇▆▅▆▅▄▇▅▇▅▅▅▅▄▅▅▅▆▅▆▆▆█▆▇▅▆▅▅▆▆▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE █▇▆▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▂▂▃▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 140.05727\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.09044\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.03853\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.09394\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgentle-dream-139\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/5i7zzh5f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_161255-5i7zzh5f/logs\u001b[0m\n",
            "100% 200/200 [8:11:16<00:00, 147.38s/it]\n",
            "Test MAE: 0.08330291555854526\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▇█▇█▇▇▇▇▇██▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇█████▇█▇███▇▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▆▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE █▆▅▃▃▂▂▃▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 123.42064\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.0833\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.04274\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.08636\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mradiant-glade-141\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/q8k7jrvs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_161255-q8k7jrvs/logs\u001b[0m\n",
            "100% 200/200 [8:12:05<00:00, 147.63s/it]\n",
            "Test MAE: 0.026244951575233117\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▇█▇█▇▇█▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇██▇████▇▇▇█▇█▇▇▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▆▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE █▄▃▃▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▂▂▁▂▂▂▁▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 115.52172\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.02624\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.02317\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.02668\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdainty-energy-139\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/zxb0x4o9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_161255-zxb0x4o9/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!source scripts/experiments/parallel_template.sh i"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
