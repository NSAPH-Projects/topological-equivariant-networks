#@package _global_
dataset:
  version: v2
  transform:
    _target_: torch_geometric.transforms.compose.Compose
    _args_:
      - - _target_: etnn.pm25.utils.create_mask
          _partial_: true
          seed: ${seed}
          rate: 0.3

model:
  # defaults, other params changed by the runtime choices such as baseline, etc
  _target_: etnn.models.ETNN
  dropout: 0.0

loader:
  _target_: torch.utils.data.DataLoader 
  num_workers: 0
  batch_size: 1
  persistent_workers: false
  pin_memory: true

collate_fn:
  _target_: etnn.combinatorial_complexes.CombinatorialComplexCollater

training:
  # defaults, other params changed by training/ config files
  max_epochs: 500
  clip: 1.0

wandb:
  entity: ten-harvard
  project: spatial-cc
  config:
    baseline: ${hydra:runtime.choices.baseline}
    seed: ${seed}
    lr: ${optimizer.lr}
    max_epochs: ${training.max_epochs}
    loss_fn: ${hydra:runtime.choices.loss_fn}
    clip: ${training.clip}

optimizer:
  _target_: torch.optim.Adam
  lr: 0.01
  weight_decay: 1e-4

lr_scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  eta_min: 0.001
  T_max: ${training.max_epochs}
