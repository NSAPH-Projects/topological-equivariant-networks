{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmLl5idn38kO",
        "outputId": "84abe8c6-5632-421c-d82d-1d31cdb682b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'topological-equivariant-networks' already exists and is not an empty directory.\n",
            "/content/topological-equivariant-networks\n"
          ]
        }
      ],
      "source": [
        "# Repo download (from colab-notebooks branch)\n",
        "%cd /content\n",
        "!git clone -b colab-notebooks https://github.com/NSAPH-Projects/topological-equivariant-networks.git\n",
        "%cd topological-equivariant-networks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AdHRWxnUORX",
        "outputId": "5cfda0e3-8cb1-4d31-982d-13ffaf5c33a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIMFu2_gDgD2",
        "outputId": "321c56ea-885d-4a95-e99b-e91255053cfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "  # Create the requirements.txt file\n",
        "%%writefile requirements.txt\n",
        "gudhi==3.8.0\n",
        "rdkit\n",
        "torch==2.1.0\n",
        "torch_geometric\n",
        "wandb\n",
        "git+https://github.com/pyt-team/TopoNetX@cede811485aefcff1d013dbb94942e8f92ac5d05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ5MWb1MEYTv",
        "outputId": "7a825d24-a696-4a5e-f29d-7b225df2d35c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/pyt-team/TopoNetX@cede811485aefcff1d013dbb94942e8f92ac5d05 (from -r requirements.txt (line 6))\n",
            "  Cloning https://github.com/pyt-team/TopoNetX (to revision cede811485aefcff1d013dbb94942e8f92ac5d05) to /tmp/pip-req-build-zkgj6kac\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyt-team/TopoNetX /tmp/pip-req-build-zkgj6kac\n",
            "  Running command git rev-parse -q --verify 'sha^cede811485aefcff1d013dbb94942e8f92ac5d05'\n",
            "  Running command git fetch -q https://github.com/pyt-team/TopoNetX cede811485aefcff1d013dbb94942e8f92ac5d05\n",
            "  Running command git checkout -q cede811485aefcff1d013dbb94942e8f92ac5d05\n",
            "  Resolved https://github.com/pyt-team/TopoNetX to commit cede811485aefcff1d013dbb94942e8f92ac5d05\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gudhi==3.8.0 (from -r requirements.txt (line 1))\n",
            "  Downloading gudhi-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit (from -r requirements.txt (line 2))\n",
            "  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.1.0 (from -r requirements.txt (line 3))\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_geometric (from -r requirements.txt (line 4))\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r requirements.txt (line 5))\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from gudhi==3.8.0->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->-r requirements.txt (line 3))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->-r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (4.2.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.1)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading sentry_sdk-2.2.0-py2.py3-none-any.whl (281 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.1/281.1 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from TopoNetX==0.0.2->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TopoNetX==0.0.2->-r requirements.txt (line 6)) (2.0.3)\n",
            "Collecting trimesh (from TopoNetX==0.0.2->-r requirements.txt (line 6))\n",
            "  Downloading trimesh-4.4.0-py3-none-any.whl (694 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.6/694.6 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spharapy (from TopoNetX==0.0.2->-r requirements.txt (line 6))\n",
            "  Downloading SpharaPy-1.1.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 5)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->-r requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->-r requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->-r requirements.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->TopoNetX==0.0.2->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TopoNetX==0.0.2->-r requirements.txt (line 6)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TopoNetX==0.0.2->-r requirements.txt (line 6)) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->-r requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: TopoNetX\n",
            "  Building wheel for TopoNetX (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TopoNetX: filename=TopoNetX-0.0.2-py3-none-any.whl size=104433 sha256=be15955bb580e8d6259124fe6807c911e71a800d2a9effa23b7e2686177d9e52\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/63/ca/e5429d5616ccfc4c1e8432dbdd21e84a23198474877d5d5663\n",
            "Successfully built TopoNetX\n",
            "Installing collected packages: spharapy, triton, trimesh, smmap, setproctitle, sentry-sdk, rdkit, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gudhi, docker-pycreds, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, torch_geometric, TopoNetX, nvidia-cusolver-cu12, gitpython, wandb, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TopoNetX-0.0.2 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 gudhi-3.8.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 rdkit-2023.9.6 sentry-sdk-2.2.0 setproctitle-1.3.3 smmap-5.0.1 spharapy-1.1.2 torch-2.1.0 torch_geometric-2.5.3 trimesh-4.4.0 triton-2.1.0 wandb-0.17.0\n"
          ]
        }
      ],
      "source": [
        "# Create the environment\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPfxlFLxVUCq",
        "outputId": "b1f45976-a372-4562-dc14-3ac584ee07f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source scripts/isolated_ranks.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cL3O3pPTOCQH",
        "outputId": "88850db1-f7a5-420b-d137-90cb4ba78b77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 42\n",
            "Number of parameters: 1497743\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=18, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/molnet_publish/qm9.zip\n",
            "Extracting datasets/QM9_CC/raw/qm9.zip\n",
            "Downloading https://ndownloader.figshare.com/files/3195404\n",
            "Processing...\n",
            "  0% 0/133885 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n",
            "100% 133885/133885 [18:01<00:00, 123.80it/s]\n",
            "Done!\n",
            "Saving lifted QM9 samples: 130831it [04:08, 525.84it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [00:49<00:00, 2010.58it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [00:47<00:00, 2085.83it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 12397.88it/s]\n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:07<00:00, 2358.81it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:08<00:00, 2122.64it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 13007.16it/s]\n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:10<00:00, 1197.61it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:06<00:00, 2074.60it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 12799.08it/s]\n",
            "=> loading checkpoint '/content/drive/MyDrive/checkpoints/checkpoint_65731be642fbd393f3ebc7d6d5f8b778.pth.tar'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240520_192318-1x62676r\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33mlegendary-lion-180\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/1x62676r\u001b[0m\n",
            "  7% 7/98 [12:00<2:36:07, 102.94s/it]Epoch 10 Test MAE: 0.666212930949065\n",
            " 17% 17/98 [29:25<2:20:21, 103.96s/it]Epoch 20 Test MAE: 0.37752015051180426\n",
            " 28% 27/98 [46:50<2:03:04, 104.01s/it]Epoch 30 Test MAE: 0.24882226421015105\n",
            " 30% 29/98 [51:51<2:03:23, 107.29s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/topological-equivariant-networks/src/main_qm9.py\", line 357, in <module>\n",
            "    main(parsed_args)\n",
            "  File \"/content/topological-equivariant-networks/src/main_qm9.py\", line 138, in main\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 433, in backward\n",
            "    def backward(\n",
            "KeyboardInterrupt\n",
            "Exception ignored in atexit callback: <function _Manager._atexit_setup.<locals>.<lambda> at 0x7c65580d8820>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_manager.py\", line 156, in <lambda>\n",
            "    self._atexit_lambda = lambda: self._atexit_teardown()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_manager.py\", line 165, in _atexit_teardown\n",
            "    self._teardown(exit_code)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_manager.py\", line 176, in _teardown\n",
            "    result = self._service.join()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/service/service.py\", line 266, in join\n",
            "    ret = self._internal_proc.wait()\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1209, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1959, in _wait\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 1917, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5b145deea8cc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source scripts/isolated_ranks.sh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m   \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m   \u001b[0minput_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgb5P7Dye3dR",
        "outputId": "b7748418-ade5-4353-85a4-e4d2822792ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set as 42\n",
            "Random seed set as 42\n",
            "Random seed set as 42\n",
            "Random seed set as 42\n",
            "Number of parameters: 1497871\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "Number of parameters: 1497871\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "Number of parameters: 1497871\n",
            "Number of parameters: 1497871\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_161255-5i7zzh5f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgentle-dream-139\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/5i7zzh5f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_161255-q8k7jrvs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mradiant-glade-141\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/q8k7jrvs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_161255-zxb0x4o9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdainty-energy-139\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/zxb0x4o9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_161255-ma1d19ia\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfancy-aardvark-141\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/ma1d19ia\u001b[0m\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:43<00:00, 964.52it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:43<00:00, 963.83it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:43<00:00, 963.68it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:43<00:00, 961.61it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:28<00:00, 1130.18it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:28<00:00, 1127.74it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:28<00:00, 1125.80it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:29<00:00, 1115.62it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11376.61it/s]\n",
            "Preparing data: 100% 100000/100000 [00:09<00:00, 11064.09it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11158.37it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11476.28it/s]\n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:21<00:00, 832.25it/s] \n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:21<00:00, 843.31it/s] \n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:21<00:00, 831.41it/s] \n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:20<00:00, 850.60it/s] \n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:16<00:00, 1080.84it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:16<00:00, 1093.34it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:16<00:00, 1086.46it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:16<00:00, 1062.99it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 11770.88it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 11704.40it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 11784.99it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 11605.60it/s]\n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:20<00:00, 653.97it/s] \n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:20<00:00, 649.23it/s] \n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:20<00:00, 646.44it/s] \n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:19<00:00, 664.99it/s] \n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1167.57it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1159.47it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1150.40it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1162.86it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11607.43it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11735.67it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11785.33it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11668.13it/s]\n",
            "100% 200/200 [8:09:15<00:00, 146.78s/it]\n",
            "Test MAE: 0.021284252554722077\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▄▆▄▅▄▆▆▅▄▆▇▅▃▅▃▂▄▃▄▄▄▃▂▃▁▃▄▄▄█▃█▄▇▄▆▅▇▅▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE ▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁█▄▄▂▂▁▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE ▅▃▃▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁█▅▄▂▂▂▇▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 146.08101\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.02128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.01752\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.02156\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfancy-aardvark-141\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/ma1d19ia\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_161255-ma1d19ia/logs\u001b[0m\n",
            "100% 200/200 [8:10:15<00:00, 147.08s/it]\n",
            "Test MAE: 0.09044490847056799\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▅▆▆▅▆▆▆▅▇▆▅▆▅▄▇▅▇▅▅▅▅▄▅▅▅▆▅▆▆▆█▆▇▅▆▅▅▆▆▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE █▇▆▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▂▂▃▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 140.05727\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.09044\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.03853\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.09394\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgentle-dream-139\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/5i7zzh5f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_161255-5i7zzh5f/logs\u001b[0m\n",
            "100% 200/200 [8:11:16<00:00, 147.38s/it]\n",
            "Test MAE: 0.08330291555854526\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▇█▇█▇▇▇▇▇██▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇█████▇█▇███▇▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▆▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE █▆▅▃▃▂▂▃▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 123.42064\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.0833\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.04274\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.08636\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mradiant-glade-141\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/q8k7jrvs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_161255-q8k7jrvs/logs\u001b[0m\n",
            "100% 200/200 [8:12:05<00:00, 147.63s/it]\n",
            "Test MAE: 0.026244951575233117\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▇█▇█▇▇█▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇██▇████▇▇▇█▇█▇▇▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▆▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE █▄▃▃▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▂▂▁▂▂▂▁▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 115.52172\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.02624\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.02317\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.02668\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdainty-energy-139\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/zxb0x4o9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_161255-zxb0x4o9/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!source scripts/isolated_ranks_parallel.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJEtaoXiyqnJ",
        "outputId": "dc1b5455-33cf-4e1d-a04a-30069545d9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR=\"5e-4\"\n",
            "\n",
            "for TARGET_NAME in \"alpha\" \"H\"\n",
            "do\n",
            "  for LIFTER in \"bond\" \"functional_group\"\n",
            "  do\n",
            "    # Train EGNN in parallel for each LIFTER\n",
            "    python src/main_qm9.py --lifters \"atom:0\" \"$LIFTER:1\" \"supercell:2\" \\\n",
            "                           --dim 2 \\\n",
            "                           --visible_dims 0 1 \\\n",
            "                           --initial_features \"hetero\" \\\n",
            "                           --target_name \"$TARGET_NAME\" \\\n",
            "                           --neighbor_types \"max\" \\\n",
            "                           --connectivity \"self\" \\\n",
            "                           --epochs 100 \\\n",
            "                           --batch_size 96 \\\n",
            "                           --weight_decay 1e-16 \\\n",
            "                           --lr \"$LR\" \\\n",
            "                           --min_lr 0 \\\n",
            "                           --num_layers 7 \\\n",
            "                           --num_hidden 128 \\\n",
            "                           --model_name \"ten\" \\\n",
            "                           --clip_gradient \\\n",
            "                           --normalize_invariants\n",
            "                           --splits \"egnn\" &\n",
            "  done\n",
            "\n",
            "  # Wait for all background processes from the inner loop to finish before proceeding to the next TARGET_NAME\n",
            "done\n",
            "wait\n"
          ]
        }
      ],
      "source": [
        "!cat scripts/isolated_ranks_parallel.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMjz8_bgEJq1",
        "outputId": "0e4d4beb-f085-4c95-c1cd-e24bcf9a506b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set as 42\n",
            "Random seed set as 42\n",
            "Random seed set as 42\n",
            "Random seed set as 42\n",
            "Number of parameters: 1497871\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "Number of parameters: 1497743\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=18, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "Number of parameters: 1497743\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=18, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "Number of parameters: 1497871\n",
            "TEN (<bound method Module.type of TEN(\n",
            "  (inv_normalizer): ModuleDict(\n",
            "    (1_1_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (0_0_2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "  )\n",
            "  (feature_embedding): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=19, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-6): 7 x EMPSNLayer(\n",
            "      (message_passing): ModuleDict(\n",
            "        (1_1_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (0_0_2): SimplicialEGNNLayer(\n",
            "          (message_mlp): Sequential(\n",
            "            (0): Linear(in_features=261, out_features=128, bias=True)\n",
            "            (1): SiLU()\n",
            "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (3): SiLU()\n",
            "          )\n",
            "          (edge_inf_mlp): Sequential(\n",
            "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (update): ModuleDict(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "          (1): SiLU()\n",
            "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_pool): ModuleDict(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (post_pool): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (1): SiLU()\n",
            "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mege-k\u001b[0m (\u001b[33mten-harvard\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_030024-kf7mxhtz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mswift-butterfly-103\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/kf7mxhtz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_030024-v0x5wy56\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msuper-breeze-104\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/v0x5wy56\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_030024-hemnqsw8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mamber-oath-104\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/hemnqsw8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/topological-equivariant-networks/wandb/run-20240519_030024-u260v5xc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgood-deluge-106\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/u260v5xc\u001b[0m\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [00:56<00:00, 1780.98it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [00:56<00:00, 1782.50it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:42<00:00, 979.68it/s]\n",
            "Reading lifted QM9 samples: 100% 100000/100000 [01:41<00:00, 980.76it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [00:55<00:00, 1793.71it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [00:56<00:00, 1784.89it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11520.78it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11599.97it/s]\n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:06<00:00, 2744.12it/s]\n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:06<00:00, 2806.12it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:08<00:00, 2008.46it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:08<00:00, 1994.11it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 12089.44it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 12035.76it/s]\n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:11<00:00, 1143.85it/s]\n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:11<00:00, 1142.80it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:06<00:00, 1988.43it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:06<00:00, 1964.88it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11725.91it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11689.63it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:30<00:00, 1106.17it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 100000/100000 [01:30<00:00, 1103.58it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11606.69it/s]\n",
            "Preparing data: 100% 100000/100000 [00:08<00:00, 11227.24it/s]\n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:21<00:00, 830.86it/s] \n",
            "Reading lifted QM9 samples: 100% 17748/17748 [00:21<00:00, 837.60it/s] \n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:15<00:00, 1135.26it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 17748/17748 [00:15<00:00, 1158.08it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 11097.67it/s]\n",
            "Preparing data: 100% 17748/17748 [00:01<00:00, 10838.84it/s]\n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:19<00:00, 662.95it/s] \n",
            "Reading lifted QM9 samples: 100% 13083/13083 [00:19<00:00, 662.33it/s] \n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1160.21it/s]\n",
            "Converting ccdicts to CombinatorialComplexData objects: 100% 13083/13083 [00:11<00:00, 1111.27it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11945.38it/s]\n",
            "Preparing data: 100% 13083/13083 [00:01<00:00, 11604.68it/s]\n",
            "100% 100/100 [3:30:33<00:00, 126.33s/it]\n",
            "100% 100/100 [3:30:37<00:00, 126.37s/it]\n",
            "Test MAE: 0.051883429751126434\n",
            "Test MAE: 0.10926103597357326\n",
            " 94% 94/100 [3:28:54<13:19, 133.30s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▁▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇█▇▇▇▇▇██▇▇▇███▇█▇▇▇██▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE █▆█▄▅▄▃▂▃▂▂▂▁▁▁▁▁▂▂▄▃▂▂▂▃▄▃▂▄▂▃▂▂▃▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 125.82644\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.05188\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.05125\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.05168\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msuper-breeze-104\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/v0x5wy56\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_030024-v0x5wy56/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE ▇█▆▅▄▅▄▃▄▃▂▂▂▂▂▂▂▂▂▂▂▂▃▃▄▂▃▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 125.51975\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.10926\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.08482\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.11466\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mamber-oath-104\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/hemnqsw8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_030024-hemnqsw8/logs\u001b[0m\n",
            "100% 100/100 [3:40:05<00:00, 132.05s/it]\n",
            "Test MAE: 0.10903236139429746\n",
            "100% 100/100 [3:40:19<00:00, 132.19s/it]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▅▆▆▇▇█▇▇▇█▇▇▇▇▇▇▇▇▇▇██▇▇▇▇█▇██▇██▇█▇▇▇▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▆▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE █▆▄▆▃▄▃▂▂▂▂▂▁▁▁▁▁▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 110.99337\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.10903\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.08212\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.11512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mswift-butterfly-103\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/kf7mxhtz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_030024-kf7mxhtz/logs\u001b[0m\n",
            "Test MAE: 0.03916431830203446\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration ▅▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██▇██▇█▇█▇▇████▇█▆▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate ██▇▇▆▆▅▄▃▂▂▁▁▁▁▂▂▃▃▄▅▆▇▇████▇▇▆▆▅▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE █▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE ▆██▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▄▂▅▂▂▂▁▂▃▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Epoch Duration 110.00827\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Learning Rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Test MAE 0.03916\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Train MAE 0.03945\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Validation MAE 0.03995\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgood-deluge-106\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan/runs/u260v5xc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ten-harvard/QM9-Super-Saiyan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_030024-u260v5xc/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!source scripts/isolated_ranks_parallel.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmW_UWNrVGlS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}